---
title: "PRA2 - Limpieza y validación de datos"
author: "Antonio Caparrini Lopez"
date: "26/12/2019"
output:
  pdf_document:
    toc: yes
  html_document:
    theme: united
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(nortest)
library(ggplot2)
library(corrplot)
library(nnet)
library(car)
library(caret)
if(!require(C50)){
    install.packages('C50', repos='http://cran.us.r-project.org')
    library(C50)
}
```

# Detalles de la actividad


## Descripción

Como parte de la asignatura *tipología de datos y ciclo de vida de los datos* dentro del máster en ciencia de datos de la UOC este documento elabora un caso práctico que consiste en el tratamiento de un conjunto de datos utilizando las herramientas disponibles para su limpieza, validación y análisis.

## Objetivos

Los objetivos concretos de esta práctica son:

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
* Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.


## Competencias

En esta práctica se desarrollan las siguientes competencias del **Master de Data Science**:

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.

# Resolución

## Descripción del dataset

```{r load_data}
winedataset <- read.csv("data/winequality-red.csv")
``` 

El conjunto de datos elegido para el análisis es el *Red Wine Quality* disponible en [**kaggle**](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009). Este conjunto de datos tiene un total de `r dim(winedataset)[1]` registros y un total de `r dim(winedataset)[2]`  columnas que pasamos a comentar a continuación:

1. **fixed acidity**: La no-volatilidad de los ácidos presentes en el vino (que no se evaporan con facilidad).
2. **volatile acidity**: Cantidad de ácido acético en el vino. Niveles muy altos llevan a un sabor desagradable a vinagre.
3. **citric acid**: En pequeñas cantidades puede dar frescura a un vino. 
4. **residual sugar**: El nivel de azúcar después de que pare la fermentación del vino. Es raro encontrar vinos con una menor a 1g/litro y los vinos con más de 45g/litro se consideran dulces.
5. **chlorides**: Cantidad de sal en el vino.
6. **free sulfur dioxide**: Cantidad de dióxido de azufre libre.
7. **total sulfur dioxide**: Cantidad de dióxido de azufre libre y ligado.
8. **density**: Suele ser cercana a la densidad del agua dependiendo de los niveles de alcohol o azúcar.
9. **pH**: Describe lo ácido o básico que es el vino. Desde 0 (muy ácido) a 14 (muy básico). Suele encontrarse en torno a 3-4. 
10. **sulphates**: Aditivos al vino que pueden contribuir al gas dióxido de azufre que tiene efectos antimicrobianos y antioxidantes. 
11. **alcohol**: Porcentaje de alcohol. 
12. **quality**: Variable de salida, medida entre 0 y 10.

Para más detalles sobre los datos referimos al trabajo original [Cortez et al., 2009](https://www.sciencedirect.com/science/article/pii/S0167923609001377).

## Importancia y objetivos de los análisis

A partir del dataset se pretender determinar las variables más relevantes a la hora de valorar la calidad de un vino. También podremos generar un modelo de regresión que partiendo de las variables del vino estime la calidad.

Este análisis es relevante para el campo de la enología (estudio del vino). Un soumiller (por ejemplo) que deba hacer una cata de vinos necesitaría una cantidad de tiempo elevada para catar una gran cantidad de vinos mientras que con un modelo previo que estime los mejores podría dedicar su esfuerzo y criterio experto en los que previamente van a ser mejores debido a sus características.

## Limpieza de los datos

Los datos los habíamos leído previamente en el apartado anterior, y mostramos un sumario de su contenido.

```{r sumario}
summary(winedataset)
```

No vamos a descartar ninguna de las variables por el momento. En primera instancia vamos a considerarlas todas como potencialmente relevantes.

Es importante ver el tipo de variables que tenemos.

```{r tipovar}
str(winedataset)
```

Vemos que las 11 variables que utilizamos para predecir son variables numéricas continuas y la variable *quality* que es el objetivo es una variable numérica entera.


### Valores nulos o vacíos.

```{r nulos}
sapply(winedataset, function(x) sum(is.na(x)))
```

Ninguna de las variables parece tener registros nulos o vacíos, sin embargo en ocasiones el valor cero puede indicar valores perdidos o nulos. Observando el sumario mostrado anteriormente de las variables vemos que solo la variable citric.acid llega a tener el valor cero. Vamos a comprobar con un boxplot que no hay muchos valores outliers hacia el cero.

```{r}
ggplot(winedataset, aes(x="citric.acid", y=citric.acid))+geom_boxplot()
```

Las demás variables queda descartado que tengan valores nulos por ceros, y en el caso de citric.acid no parecen que el valor cero sea incorrecto. Lo que si podemos percibir en este boxplot es un punto que parece un valor extremo ("outlier").

### Valores extremos

Los valores extremos ("outliers") son valores que debido a ser considerablemente distintos al resto de los datos podría considerarse que no perteneces a la población. Para identificarlos podríamos dibujar los boxplots para todas las variables (como se ha visto en el apartado anterior para la variable citric.acid) pero también podemos utilizar la función boxplot.stats() que nos muestra directamente los valores extremos:

```{r}
for (c in colnames(winedataset)){
  print(c)
  print(boxplot.stats(winedataset[,c])$out)
}
```

Podemos observar (entre otros) que el citric.acid con valor 1 es un outlier. Para no eliminar estos datos del dataset vamos a asignarles el valor de percentil 5% a los que sean valores extremos inferiores y el valor del percentil 95% a los valores extremos superiores.

```{r}
cut_outliers <- function(x){
  quantiles <- quantile( x, c(.05, .95))
  x[ x < quantiles[1]] <- quantiles[1]
  x[ x > quantiles[2]] <- quantiles[2]
  return(x)
}

winedataset <- as.data.frame( sapply(winedataset, cut_outliers) )
```

La variable objetivo tenía muchos valores extremos que hemos filtrado también, quedando de la siguiente manera.

```{r}
ggplot(winedataset, aes(x=quality)) + geom_histogram()
```

Por ello vamos a tratar esta variable como una variable categórica con 3 clases.


## Análisis de los datos

### Comprobación de normalidad

Comprobamos si alguna de las variables cumple las características de una distribución normal. Para ello aplicamos el test de [Shaphiro-Wilk](https://en.wikipedia.org/wiki/Shapiro–Wilk_test). Aplicando este test la hipótesis nula es que la distribución cumple normalidad, por ello, para no rechazar la hipótesis nula el p-valor tiene que ser mayor que el nivel de significación elegido (alpha=0.05).
```{r normaldist}
alpha <- 0.05
for(n in names(winedataset)[-12]){
  pvalue <- shapiro.test(winedataset[,n])$p.value
  if(pvalue>alpha){
    cat("Variable ", n, " SI es normal\n")
    print(shapiro.test(winedataset[,n]))
  }else{
    cat("Variable ", n, " NO cumple una distribución normal\n")
  }
}
```

Vemos que según este test ninguna variable cumple una distribución normal, probamos con el test de Anderson-Darling.

```{r normaldistad}
alpha <- 0.05
for(n in names(winedataset)[-12]){
  pvalue <- ad.test(winedataset[,n])$p.value
  if(pvalue>alpha){
    cat("Variable ", n, " SI es normal\n")
    print(shapiro.test(winedataset[,n]))
  }else{
    cat("Variable ", n, " NO cumple una distribución normal\n")
  }
}
```

### Comprobación de homogeneidad en la varianza

Dado que las variables que tenemos no siguen una distribución normal vamos a utilizar el test de Levene que es ampliamente utilizado en la literatura para comprobar la homogeneidad de las varianzas de las variables.

```{r}
alpha <- 0.05
for(n in names(winedataset)[-12]){
  pvalue <- leveneTest(winedataset[,n] ~ as.factor(winedataset$quality))$Pr[1]
  if(is.nan(pvalue)){
    pvalue <- 0
  }
  if(pvalue>alpha){
    cat("Variable ", n, " SI tiene una varianza homogénea\n")
    print(leveneTest(winedataset[,n] ~ as.factor(winedataset$quality))$Pr[1])
  }else{
    cat("Variable ", n, " NO tiene una varianza homogénea\n")
  }
}
```

Tenemos 3 variables que tienen una varianza homogénea chlorides, pH y sulphates.

## Pruebas estadísticas

Es interesante comprobar la capacidad explicativa de la *quality* para cada variable. Para ello vamos a calcular los coeficientes de correlación de Spearman. Es necesario utilizar los de Spearman ya que nos encontramos con variables que no siguen una distribución normal.

```{r corr}
corrplot(cor(winedataset, method = c("spearman")), method = "number", tl.pos = 'l', tl.cex= 0.5)
```

Nos encontramos con dos variables que estan positivamente correlacionadas con la calidad que son *alcohol* y *sulphates*. Estas dos variables tienen la mayor correlación positiva por lo que a mayor nivel de estas dos mayor calidad en el vino.

Por otro lado la variable *volatile.acidity* tiene la mayor correlación negativa indicando que a mayor nivel de esta la calidad es menor. Como veíamos en la descripción de las variables esta es la cantidad de ácido acético en el vino que a mayor cantidad, mayor sabor a vinagre. Este relación es por tanto razonable.

Correlación positiva algo inferior tenemos *fixed.acidity* y *citric.acid*.

Y con una correlación negativa pero también pequeña *chlorides*, *total.sulfur.dioxide* y *density*.

### Regressión lineal

Vamos a crear un modelo de regresión lineal que estime la calidad del vino. Para ello vamos a crear 11 modelos distintos y quedarnos con el mejor. Como criterio de construcción vamos a ir añadiendo las variables con el coeficiente de correlación mayor en valor absoluto.


```{r lm}
winedataset$quality <- sapply(winedataset$quality, as.numeric)


cor_data <- cor(winedataset, method = c("spearman"))

quality_cor <- sort(abs(cor_data[, "quality"]))
vars_names <- names(quality_cor)



model11 <- lm(quality ~ residual.sugar + pH + free.sulfur.dioxide 
              + fixed.acidity + density + 
                chlorides + total.sulfur.dioxide + citric.acid 
              + sulphates + volatile.acidity + alcohol,
              data=winedataset)
model10 <- lm(quality ~ pH + free.sulfur.dioxide + fixed.acidity + density + 
                chlorides + total.sulfur.dioxide + citric.acid 
              + sulphates + volatile.acidity + alcohol,
              data=winedataset)
model9 <- lm(quality ~ free.sulfur.dioxide + fixed.acidity + density + 
                chlorides + total.sulfur.dioxide + citric.acid 
             + sulphates + volatile.acidity + alcohol,
              data=winedataset)
model8 <- lm(quality ~ fixed.acidity + density + 
                chlorides + total.sulfur.dioxide + citric.acid 
             + sulphates + volatile.acidity + alcohol,
              data=winedataset)
model7 <- lm(quality ~ density + 
                chlorides + total.sulfur.dioxide + citric.acid 
             + sulphates + volatile.acidity + alcohol,
              data=winedataset)
model6 <- lm(quality ~ chlorides + total.sulfur.dioxide + 
               citric.acid + sulphates + volatile.acidity +
               alcohol, data=winedataset)
model5 <- lm(quality ~ total.sulfur.dioxide + citric.acid + 
               sulphates + volatile.acidity + alcohol, data=winedataset)
model4 <- lm(quality ~ citric.acid + sulphates + 
               volatile.acidity + alcohol, data=winedataset)
model3 <- lm(quality ~ sulphates + volatile.acidity + alcohol, data=winedataset)
model2 <- lm(quality ~ volatile.acidity + alcohol, data=winedataset)
model1 <- lm(quality ~ alcohol, data=winedataset)
```

En la tabla a continuación visualizamos el valor de R^2 de todos los modelos. EL mejor modelo sería el que tenga el valor mayor que en este caso es el que utiliza todas las variables.
```{r}
tabla.coeficientes <- matrix(c(
  1, summary(model1)$r.squared, 
  2, summary(model2)$r.squared,
  3, summary(model3)$r.squared,
  4, summary(model4)$r.squared,
  5, summary(model5)$r.squared,
  6, summary(model6)$r.squared,
  7, summary(model7)$r.squared,
  8, summary(model8)$r.squared,
  9, summary(model9)$r.squared,
  10, summary(model10)$r.squared,
  11, summary(model11)$r.squared), ncol = 2, byrow = TRUE)

colnames(tabla.coeficientes) <- c("Modelo", "R^2")
tabla.coeficientes
```


El anterior modelo era de regresión, ahora vamos a crear un modelo de regresión pero de clasificación multilabel.

```{r multinom, include=FALSE}

mmodel11 <- multinom(quality ~ residual.sugar + pH + free.sulfur.dioxide 
              + fixed.acidity + density + 
                chlorides + total.sulfur.dioxide + citric.acid 
              + sulphates + volatile.acidity + alcohol,
              data=winedataset)
mmodel10 <- multinom(quality ~ pH + free.sulfur.dioxide + fixed.acidity + density + 
                chlorides + total.sulfur.dioxide + citric.acid 
              + sulphates + volatile.acidity + alcohol,
              data=winedataset)
mmodel9 <- multinom(quality ~ free.sulfur.dioxide + fixed.acidity + density + 
                chlorides + total.sulfur.dioxide + citric.acid 
             + sulphates + volatile.acidity + alcohol,
              data=winedataset)
mmodel8 <- multinom(quality ~ fixed.acidity + density + 
                chlorides + total.sulfur.dioxide + citric.acid 
             + sulphates + volatile.acidity + alcohol,
              data=winedataset)
mmodel7 <- multinom(quality ~ density + 
                chlorides + total.sulfur.dioxide + citric.acid 
             + sulphates + volatile.acidity + alcohol,
              data=winedataset)
mmodel6 <- multinom(quality ~ chlorides + total.sulfur.dioxide + 
               citric.acid + sulphates + volatile.acidity +
               alcohol, data=winedataset)
mmodel5 <- multinom(quality ~ total.sulfur.dioxide + citric.acid + 
               sulphates + volatile.acidity + alcohol, data=winedataset)
mmodel4 <- multinom(quality ~ citric.acid + sulphates + 
               volatile.acidity + alcohol, data=winedataset)
mmodel3 <- multinom(quality ~ sulphates + volatile.acidity + alcohol, data=winedataset)
mmodel2 <- multinom(quality ~ volatile.acidity + alcohol, data=winedataset)
mmodel1 <- multinom(quality ~ alcohol, data=winedataset)
```

En la siguiente tabla vemos el valor de AIC de todos los modelos creados, el que tenga una AIC menor será el mejor modelo.

```{r}
tabla.coeficientes <- matrix(c(
  1, summary(mmodel1)$AIC, 
  2, summary(mmodel2)$AIC,
  3, summary(mmodel3)$AIC,
  4, summary(mmodel4)$AIC,
  5, summary(mmodel5)$AIC,
  6, summary(mmodel6)$AIC,
  7, summary(mmodel7)$AIC,
  8, summary(mmodel8)$AIC,
  9, summary(mmodel9)$AIC,
  10, summary(mmodel10)$AIC,
  11, summary(mmodel11)$AIC), ncol = 2, byrow = TRUE)

colnames(tabla.coeficientes) <- c("Modelo", "AIC")
tabla.coeficientes
```

Con el proposito de tener una comparación visual de estos dos modelos seleccionamos aleatoriamente 10 registros del conjunto de datos y mostramos una tabla con la calidad real, la detectada por el modelo de regresión y por el modelo de clasificación.

```{r example}
my_index <- sample(1:1599,10)
elements <- winedataset[my_index,]
pred_model <- predict(model11, elements)
pred_mmodel <- predict(mmodel6, elements)
cbind(my_index, pred_model, pred_mmodel, label=winedataset$quality[my_index])
```

A pesar de que las etiquetas reales son enteras el modelo de regresión nos da una información más detallada ya que existen valores continuos entre una clase y otra (que podría relacionarse con la probabilidad de pertenecer a una clase que el modelo de clasificación acaba redondeando).


### Árbol de decisión

Vamos a probar un árbol de decisión, en primer lugar para ello partimos el conjunto en conjunto para entrenar y el conjunto donde comprobaremos la capacidad predictiva del modelo.

```{r}
winedataset$quality <- sapply(winedataset$quality, as.factor)

train_index <- sample(1:nrow(winedataset), 0.8 * nrow(winedataset))
test_index <- setdiff(1:nrow(winedataset), train_index)

X_train <- winedataset[train_index, -12]
y_train <- winedataset[train_index, 12]

X_test <- winedataset[test_index, -12]
y_test <- winedataset[test_index, 12]
```
```{r}
model <- C50::C5.0(X_train, y_train)
summary(model)
```

Comprobamos el poder predictivo.

```{r}
predictions_train <- predict(model, X_train, type="class")
accuracy_train <- 100*sum(predictions_train == y_train) / length(predictions_train)
predictions_test <- predict(model, X_test, type="class")
accuracy_test <- 100*sum(predictions_test == y_test) / length(predictions_test)
print(sprintf("La precisión del árbol en entrenamiento es: %.4f %%", accuracy_train))
print(sprintf("La precisión del árbol en prueba es: %.4f %%", accuracy_test))
```
Vemos que sobre el conjunto de entrenamiento la accuracy ha sido mejor pero se degrada sobre el conjunto de prueba.

```{r}
cm <- table(y_test,Predicted=predictions_test)
#El paquete caret nos ofrece estadísticas sobre la matrix de confusión
confusionMatrix(cm)
```

# Conclusiones

En primer lugar se ha verificado que las variables del dataset no contenían valores nulos y que todas eran candidatas a aportar información en el análisis. Hemos cambiado los valores outliers por los percentiles 5% y 95% respectivamente para lo valores extremos inferiores y superiores, entre los que también se encontraba la variable objetivo.

Se ha confirmado mediante test estadísticos la no normalidad de las variables y se ha empleado los coeficientes de correlación de Spearman para ver las variables más influyentes en la calidad. De esta manera hemos visto que el grado de alcohol y los sulfitos tienes un efecto positivo en la calidad, mientras que la cantidad de ácido acético influye en la disminución de la calidad.

Por otro lado se han creado dos modelos de regresión para estimar la calidad. Estos modelos no tienen una gran capacidad predictiva pero como se menciono en la introducción pueden ser utilizados para disminuir la cantidad de vinos que ha de catar un experto a los inicialmente estimados por el modelo.

Finalmente hemos creado un árbol de decisión con una precisión balanceada del 70% entre las 3 clases que es razonable ya que un clasificador que tuviera un criterio aleatorio al elegir entre tres clases tendría una precisión del 33%.